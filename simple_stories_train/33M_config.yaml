train_dataset_config:
  name: lennart-finke/SimpleStories
  is_tokenized: false
  tokenizer_file_path: tokenizer/bpe-stories-4096.json
  split: train
  streaming: false
  n_ctx: 512
  seed: 0
  column_name: story
val_dataset_config:
  name: lennart-finke/SimpleStories
  is_tokenized: false
  tokenizer_file_path: tokenizer/bpe-stories-4096.json
  split: test
  streaming: false
  n_ctx: 512
  seed: 0
  column_name: story
model_name: 33M
# 1 GPU
batch_size: 64
total_batch_size: 32768 # 64 * 512
num_iterations: 60000 # custom iterations, reload the train loader if we exhaust data
warmup_iters: 600
# # 4 GPUs
# batch_size: 64
# total_batch_size: 262144 # 64 * 1024 * 4
# num_iterations: 2410 # (617806 dataset rows / 64 batch size / 4)
# warmup_iters: 50
learning_rate: 1e-4
learning_rate_decay_frac: 0.1
weight_decay: 0.1
grad_clip: 1.0
val_loss_every: 50
val_max_steps: 20
sample_every: 100
intermediate_checkpoints: false
